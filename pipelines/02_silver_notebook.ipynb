{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf1d39c2-edb7-4450-bb29-ed75d78a4065",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Camada Silver - Data Quality e Conformidade\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "A Camada Silver é o núcleo de higienização e conformidade do nosso Data Lakehouse. Este notebook consome os dados brutos da Camada Bronze e aplica um **Motor Universal de Data Quality (DQ)**. O objetivo é transformar textos sujos e dados legados em informações tipadas, confiáveis e prontas para cálculos financeiros ou modelagem de Machine Learning.\n",
    "\n",
    "## Lógica do Motor de Data Quality (DQ)\n",
    "O pipeline não utiliza *hardcode* de colunas. Ele lê os metadados dinamicamente e aplica 3 regras universais:\n",
    "1. **Limpeza Financeira (`DecimalType`):** Identifica colunas de moedas (sufixo `_R$` ou `_U$`), remove os pontos de milhar, substitui a vírgula decimal por ponto e aplica o casting seguro para `Decimal(18,2)`.\n",
    "2. **Time Travel Parsing (`DateType`):** Identifica colunas temporais (prefixo `DATA_`), higieniza strings anômalas (ex: \"Não informada\") e converte o padrão de texto brasileiro (`dd/MM/yyyy`) para o formato nativo de datas.\n",
    "3. **Extermínio de Magic Strings (Nullification):** Sistemas governamentais preenchem lacunas com valores fictícios. O script possui um dicionário de anomalias conhecidas (`[\"-1\", \"-3\", \"Sem informação\", \"Inválido\", \"\"]`) e as converte massivamente para verdadeiros `NULL`s do banco de dados, evitando agrupamentos fantasmas nos modelos analíticos.\n",
    "\n",
    "## Decisões de Engenharia\n",
    "* **Schema Evolution:** A transição de tipos primitivos (de `StringType` na Bronze para `DecimalType` e `DateType` na Silver) aciona a trava de segurança nativa do Delta Lake (*Schema Enforcement*). Para permitir essa alteração de contrato de forma gerida, utilizamos a *flag* `.option(\"overwriteSchema\", \"true\")`.\n",
    "* **Particionamento:** A arquitetura mantém a partição nativa por `posicao_base`, essencial para a performance das queries do time de negócios.\n",
    "\n",
    "---\n",
    "**Origem:** Tabelas gerenciadas Delta (`public_informations.bronze_...`)\n",
    "\n",
    "**Destino:** Tabelas tipadas e limpas (`public_informations.silver_...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a304cd6d-a4d3-4c5e-9078-dfb0f9fc692d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-25 22:02:41,715 - Iniciando pipeline Avançado da Camada Silver...\n2026-02-25 22:02:41,718 - Iniciando transformação Silver c/ DQ para o domínio: CADASTRO\n2026-02-25 22:02:56,085 -  -> ✅ Tabela public_informations.silver_cadastro processada, limpa e catalogada com sucesso!\n2026-02-25 22:02:56,085 - Iniciando transformação Silver c/ DQ para o domínio: REMUNERACAO\n2026-02-25 22:03:09,820 -  -> ✅ Tabela public_informations.silver_remuneracao processada, limpa e catalogada com sucesso!\n2026-02-25 22:03:09,821 - Iniciando transformação Silver c/ DQ para o domínio: AFASTAMENTOS\n2026-02-25 22:03:13,390 -  -> ✅ Tabela public_informations.silver_afastamentos processada, limpa e catalogada com sucesso!\n2026-02-25 22:03:13,391 - Iniciando transformação Silver c/ DQ para o domínio: OBSERVACOES\n2026-02-25 22:03:17,136 -  -> ✅ Tabela public_informations.silver_observacoes processada, limpa e catalogada com sucesso!\n2026-02-25 22:03:17,137 - Pipeline Silver finalizado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DecimalType\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "SCHEMA_NAME = \"public_informations\"\n",
    "DOMAINS = [\"cadastro\", \"remuneracao\", \"afastamentos\", \"observacoes\"]\n",
    "\n",
    "# Lista de lixos conhecidos do SIAPE\n",
    "VALORES_ANOMALOS = [\"-1\", \"-3\", \"Sem informação\", \"Sem informaç\", \"null\", \"NULL\", \"Inválido\", \"Não informada\", \"\"]\n",
    "\n",
    "def transform_to_silver_with_dq():\n",
    "    for domain in DOMAINS:\n",
    "        logger.info(f\"Iniciando transformação Silver c/ DQ para o domínio: {domain.upper()}\")\n",
    "        \n",
    "        bronze_table = f\"{SCHEMA_NAME}.bronze_{domain}\"\n",
    "        silver_table = f\"{SCHEMA_NAME}.silver_{domain}\"\n",
    "        \n",
    "        try:\n",
    "            df = spark.read.table(bronze_table)\n",
    "            \n",
    "            for col in [\"ANO\", \"MES\"]:\n",
    "                if col in df.columns:\n",
    "                    df = df.drop(col)\n",
    "            \n",
    "            # --- MOTOR DE DATA QUALITY UNIVERSAL ---\n",
    "            for col_name in df.columns:\n",
    "                \n",
    "                # Converte R$/U$ para Decimal(18,2)\n",
    "                if \"_R$\" in col_name or \"_U$\" in col_name:\n",
    "                    df = (df\n",
    "                          .withColumn(col_name, F.regexp_replace(F.col(col_name), r'\\.', ''))\n",
    "                          .withColumn(col_name, F.regexp_replace(F.col(col_name), r'\\,', '.'))\n",
    "                          .withColumn(col_name, F.col(col_name).cast(DecimalType(18, 2))))\n",
    "                \n",
    "                # Converte string 'dd/MM/yyyy' para DateType\n",
    "                elif col_name.startswith(\"DATA_\"):\n",
    "                    # Primeiro, limpa strings estranhas como \"Não informada\", depois converte para data\n",
    "                    df = df.withColumn(col_name, F.when(F.col(col_name).isin(VALORES_ANOMALOS), F.lit(None))\n",
    "                                                  .otherwise(F.col(col_name)))\n",
    "                    df = df.withColumn(col_name, F.to_date(F.col(col_name), \"dd/MM/yyyy\"))\n",
    "                \n",
    "                # Transforma lixo em NULL\n",
    "                # Aplica apenas em colunas de string (que não sejam arquivo/posicao)\n",
    "                elif dict(df.dtypes)[col_name] == 'string' and col_name not in [\"arquivo_origem\", \"posicao_base\"]:\n",
    "                    df = df.withColumn(col_name, F.when(F.col(col_name).isin(VALORES_ANOMALOS), F.lit(None))\n",
    "                                                  .otherwise(F.col(col_name)))\n",
    "\n",
    "            # Adição de Metadados da Silver\n",
    "            df_silver = df.withColumn(\"timestamp_carga_silver\", F.current_timestamp())\n",
    "            \n",
    "            # Salva a Tabela Gerenciada na Camada Silver\n",
    "            (df_silver.write\n",
    "             .format(\"delta\")\n",
    "             .mode(\"overwrite\")\n",
    "             .option(\"overwriteSchema\", \"true\")\n",
    "             .partitionBy(\"posicao_base\")\n",
    "             .saveAsTable(silver_table))\n",
    "            \n",
    "            logger.info(f\" -> ✅ Tabela {silver_table} processada, limpa e catalogada com sucesso!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\" -> ❌ Erro ao processar a tabela {domain.upper()}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Iniciando pipeline Avançado da Camada Silver...\")\n",
    "    transform_to_silver_with_dq()\n",
    "    logger.info(\"Pipeline Silver finalizado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}