# üöÄ Data Engineering Challenge - SIAPE

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache_Spark-FFFFFF?style=for-the-badge&logo=apachespark&logoColor=#E35A16)
![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)
![Delta Lake](https://img.shields.io/badge/Delta_Lake-00AEEF?style=for-the-badge&logo=deltalake&logoColor=white)

## Vis√£o Geral do Projeto
Este reposit√≥rio cont√©m a solu√ß√£o arquitetural e o c√≥digo fonte para o desafio de Engenharia de Dados. O objetivo do projeto foi ingerir, higienizar e modelar a complexa base de dados de Servidores P√∫blicos Federais (SIAPE), transformando dados legados do governo em um **Produto de Dados** de alto valor para os times de **Modelagem de Risco** e **Pol√≠ticas de Cr√©dito**.

---

## Arquitetura e Decis√µes de Engenharia

O projeto foi constru√≠do sobre a arquitetura **Medallion Lakehouse** utilizando **Databricks Volumes** para governan√ßa de arquivos brutos e **Delta Lake** para as tabelas gerenciadas. O foco do desenvolvimento foi escalabilidade, resili√™ncia e autonomia.



### 1. Extract & Load: Ingest√£o Aut√¥noma e Gest√£o de Mem√≥ria (`00_ingestion`)
* **Dinamismo Temporal (M-2):** Desenvolvi um motor matem√°tico que identifica o dia de execu√ß√£o e recua estrategicamente a safra para coletar sempre a posi√ß√£o atual (M-2) e 3 meses de hist√≥rico, garantindo que o pipeline possa rodar agendado sem interven√ß√£o humana.
* **Preven√ß√£o de Gargalos (OOM):** Para evitar *Out of Memory* no processamento de ZIPs gigabytes do governo, implementei requisi√ß√µes HTTP via *Streaming* integradas ao m√≥dulo `BytesIO`, realizando a extra√ß√£o dos CSVs diretamente na **Mem√≥ria RAM** sem onerar o disco f√≠sico do cluster.
* **Hive Partitioning F√≠sico:** Os arquivos s√£o roteados para subdiret√≥rios no formato `posicao_base=YYYYMM`, pavimentando o terreno para o *Native Partition Discovery* do Spark nas pr√≥ximas camadas.

### 2. Camada Bronze: Landing e Lineage (`01_bronze`)
* **Sanitiza√ß√£o Universal de Esquemas:** Fun√ß√µes com RegEx varrem e higienizam caracteres inv√°lidos nos cabe√ßalhos originais, impedindo que o Delta Lake corrompa por mudan√ßas n√£o avisadas pelo governo.
* **Data Lineage:** Uso nativo do `_metadata.file_path` do Apache Spark para carimbar a linhagem de origem do dado em cada registro (Auditoria Row-Level).

### 3. Camada Silver: Motor de Data Quality Din√¢mico (`02_silver`)
Para proteger os modelos preditivos de *Garbage In, Garbage Out*, criei um Motor de DQ Universal (agn√≥stico ao dom√≠nio):
* **Exterm√≠nio de Magic Strings:** Identifica e anula dados fict√≠cios governamentais (`-1`, `Sem informa√ß√£o`, `N√£o informada`), convertendo-os em verdadeiros `NULLs` relacionais, impedindo agrupamentos em "estados fantasmas" pela Intelig√™ncia Artificial.
* **Schema Evolution & Casting Rigoroso:** Varredura din√¢mica de metadados. Converteu massivamente colunas financeiras (com formata√ß√£o PT-BR) para `DecimalType(18,2)` e aplicou *Time Travel Parsing* para `DateType`. A trava de *Schema Enforcement* do Delta foi manipulada com seguran√ßa via `.option("overwriteSchema")`.

### 4. Camada Gold: Business Model & OBT (`03_gold`)
* **The Big Join (OBT):** Cria√ß√£o de uma *One Big Table* tendo a tabela de `Cadastro` como espinha dorsal, absorvendo a complexidade relacional que antes reca√≠a sobre os Analistas e Cientistas de Dados.
* **Preven√ß√£o de Fan-out (Explos√£o Cartesiana):** Tabelas sat√©lites de comportamento (como Afastamentos e Observa√ß√µes) foram pr√©-agregadas antes dos `JOINs`, criando vari√°veis bin√°rias (*Flags* booleanas) que impedem a duplica√ß√£o indevida da renda do servidor e s√£o altamente otimizadas para os algoritmos de Credit Scoring.
* **Business Naming:** Renomea√ß√£o sem√¢ntica de todas as features para a linguagem de dom√≠nio dos *Stakeholders*.

---

## O Valor Gerado (Analytics)
Al√©m do pipeline de engenharia, foi desenvolvido um Jupyter Notebook de Analytics (`04_metricas_gold`) consumindo diretamente a Camada Gold via SQL, provando a efic√°cia do modelo de dados criado. Foram respondidas quest√µes como:
1. **Term√¥metro de Risco por Estabilidade:** Cruzamento da estabilidade do servidor (ex: Tempor√°rio vs. Aposentado) com a taxa mensal de afastamentos.
2. **Mapa de Calor Comercial:** Top 10 Estados com maior Massa Salarial L√≠quida.
3. **Radar High-Ticket:** √ìrg√£os de origem (ex: Banco Central) que possuem o maior Ticket M√©dio salarial para embasar limites autom√°ticos de Cart√µes Black/Premium.

---

## Governan√ßa e Contratos de Dados
Na pasta `/caatalog`, voc√™ encontrar√° o arquivo `.yml` da nossa tabela final. Todas as colunas possuem tipagem forte, descri√ß√µes sem√¢nticas e mapeamento de depend√™ncias, prontos para integra√ß√£o com dbt Docs ou DataHub.

---

## Como Executar
1. Clone este reposit√≥rio no seu Databricks Workspace.
2. Garanta a exist√™ncia de um Volume no Unity Catalog (`/Volumes/workspace/default/staging-siape-tables`).
3. Execute os notebooks na pasta `/pipelines` em ordem sequencial (00 ao 03).
4. Para consumir os insights, abra a pasta `/analytics` e execute o notebook 04.